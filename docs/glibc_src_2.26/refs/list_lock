<def f='glibc_src_2.26/malloc/arena.c' l='97' macro='1' type='__libc_lock_t'/>
<use f='glibc_src_2.26/malloc/arena.c' l='153' c='__malloc_fork_lock_parent'/>
<use f='glibc_src_2.26/malloc/arena.c' l='153' c='__malloc_fork_lock_parent'/>
<use f='glibc_src_2.26/malloc/arena.c' l='153' c='__malloc_fork_lock_parent'/>
<use f='glibc_src_2.26/malloc/arena.c' l='153' c='__malloc_fork_lock_parent'/>
<use f='glibc_src_2.26/malloc/arena.c' l='178' c='__malloc_fork_unlock_parent'/>
<use f='glibc_src_2.26/malloc/arena.c' l='178' c='__malloc_fork_unlock_parent'/>
<use f='glibc_src_2.26/malloc/arena.c' l='178' c='__malloc_fork_unlock_parent'/>
<use f='glibc_src_2.26/malloc/arena.c' l='178' c='__malloc_fork_unlock_parent'/>
<use f='glibc_src_2.26/malloc/arena.c' l='209' u='w' c='__malloc_fork_unlock_child'/>
<use f='glibc_src_2.26/malloc/arena.c' l='733' c='_int_new_arena'/>
<use f='glibc_src_2.26/malloc/arena.c' l='733' c='_int_new_arena'/>
<use f='glibc_src_2.26/malloc/arena.c' l='733' c='_int_new_arena'/>
<use f='glibc_src_2.26/malloc/arena.c' l='733' c='_int_new_arena'/>
<use f='glibc_src_2.26/malloc/arena.c' l='743' c='_int_new_arena'/>
<use f='glibc_src_2.26/malloc/arena.c' l='743' c='_int_new_arena'/>
<use f='glibc_src_2.26/malloc/arena.c' l='743' c='_int_new_arena'/>
<use f='glibc_src_2.26/malloc/arena.c' l='743' c='_int_new_arena'/>
<doc f='glibc_src_2.26/malloc/arena.c' l='85'>/* list_lock prevents concurrent writes to the next member of struct
   malloc_state objects.

   Read access to the next member is supposed to synchronize with the
   atomic_write_barrier and the write to the next member in
   _int_new_arena.  This suffers from data races; see the FIXME
   comments in _int_new_arena and reused_arena.

   list_lock also prevents concurrent forks.  At the time list_lock is
   acquired, no arena lock must have been acquired, but it is
   permitted to acquire arena locks subsequently, while list_lock is
   acquired.  */</doc>
